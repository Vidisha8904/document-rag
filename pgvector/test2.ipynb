{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Run the next cells to load data and query.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup (Run once per session)\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "key=os.getenv(\"OPENAI_API_KEY\")\n",
    "# Database connection parameters\n",
    "DB_PARAMS = {\n",
    "    \"dbname\": \"new1\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"vidisha\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"  # Change to \"5433\" if your docker-compose.yml uses \"5433:5432\"\n",
    "}\n",
    "\n",
    "# Initialize the embedding model (nomic-embed-text-v1 uses 768 dimensions)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs={'trust_remote_code': True}\n",
    ")\n",
    "\n",
    "# Initialize the LLM (replace with your OpenAI API key)\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    openai_api_key=key # Replace with your key\n",
    ")\n",
    "\n",
    "# Prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=\"\"\"\n",
    "            You are an AI assistant that helps users understand PDF documents. \n",
    "            \n",
    "            **IMPORTANT: Response Format**  \n",
    "            - If you don't find relevant information: **\"No relevant information found in the provided PDFs.\"**  \n",
    "            - After stating the sources, provide a detailed and structured answer.\n",
    "            \n",
    "            **Rules for Answering:**  \n",
    "            - Use **only** the provided context to generate responses.   \n",
    "            - If the answer is **not available**, state: **\"Answer is not available in the context.\"**\n",
    "            - If the query involves **calculations**, perform them and provide the exact result.    \n",
    "            - If the query is **unclear**, ask for clarification instead of making assumptions.  \n",
    "            \n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Query:\n",
    "    {query}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Setup complete. Run the next cells to load data and query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database table and index created. Run the next cell to load documents.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Database Connection and Table Setup (Run once, or when resetting the table)\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create or reset the documents table (768 dimensions for nomic-embed-text-v1)\n",
    "cur.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS documents;  -- Remove this line if you want to keep existing data\n",
    "    CREATE TABLE documents (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        content TEXT NOT NULL,\n",
    "        embedding VECTOR(768)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Add an index for efficient semantic search\n",
    "cur.execute(\"\"\"\n",
    "    CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops)\n",
    "WITH (m = 16, ef_construction = 200);\n",
    "\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Database table and index created. Run the next cell to load documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and stored 112 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load and Store Documents (Run once per file, or skip if data is already loaded)\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "file_path = \"QUIZ 2017-18.pdf\"  # Changed to PDF file\n",
    "\n",
    "# Load and split the document\n",
    "reader = PdfReader(file_path)\n",
    "# Extract text from all pages\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "# Create a document object similar to what TextLoader would produce\n",
    "from langchain.docstore.document import Document\n",
    "documents = [Document(page_content=text)]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Store in the database\n",
    "# Store in the database with the correct vector format\n",
    "for doc in texts:\n",
    "    embedding = embedding_model.embed_query(doc.page_content)\n",
    "    # Format the embedding as a PostgreSQL-compatible vector\n",
    "    embedding_str = f\"[{','.join(map(str, embedding))}]\"\n",
    "\n",
    "    cur.execute(\n",
    "        \"INSERT INTO documents (content, embedding) VALUES (%s, %s::vector)\",\n",
    "        (doc.page_content, embedding_str)\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "print(f\"Loaded and stored {len(texts)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar document chunks:\n",
      "Distance: 1.0211\n",
      "Content: Abhinav Bindra  \n",
      "453) When is National Safety Day Observed?      \n",
      "   4th March  \n",
      "454) Which is the Highest Plat eau in the World?     \n",
      "   Pamir ( Tibet ian Plateau)  \n",
      "455) What is the Expansion of CSIR?       \n",
      "   Council of Scientific and Industrial Research  \n",
      "456) Who is the present CEO of Britannia?      \n",
      "   Varun Berry  \n",
      "457) What is Characterology?        \n",
      "   Study of Personal  Character  \n",
      "458) Who wrote the book, “The race of My Life”?     \n",
      "   Milkha Singh\n",
      "\n",
      "Distance: 1.0462\n",
      "Content: Assam  \n",
      "106) Which is the Highest Gallantry Award in India?    \n",
      "   Param Vi r Chakra  \n",
      "107) When is National Statistics Day Celebrated?     \n",
      "   29th June \n",
      "108) What is the expansion of USB?       \n",
      "   Universal Serial Bus  \n",
      "109) Who was the first Indian to become the member of the British \n",
      "Parliament?           \n",
      "   Dadabhai Naoroji  \n",
      "110) What is the Total Duration of Foot ball Match?     \n",
      "   2 Hours & 45 Minutes  \n",
      "111) Who wrot e the book, “Discovery of India”?\n",
      "\n",
      "Distance: 1.0523\n",
      "Content: 440) What is Hydrobi ology?         \n",
      "   Study of Aquatic Organisms  \n",
      "441) Where is India’s  First Und erground Metro Railways system \n",
      "established?           \n",
      "   Kolkata  \n",
      "442) Who is the present central Minister of Commerce and  Industry?  \n",
      "   Suresh Prabhu  \n",
      "443) What is Arthrology?         \n",
      "   Study of Joints  \n",
      "444) Who wrote the Book, “Making India Awesome”?    \n",
      "   Chetan Bhagat  \n",
      "445) Who won 2017 Rajiv Gandhi khel Ratna Award for Hockey?  \n",
      "   Sardar Singh\n",
      "\n",
      "Distance: 1.0561\n",
      "Content: 404) What is A chluophobia?         \n",
      "   Fear of Darknes s \n",
      "405) Which country institutes Magsaysay Award?     \n",
      "   The Philippines    \n",
      "406) Which is the capital of Australia?       \n",
      "   Canberra     \n",
      "407) What is Tachophobia?         \n",
      "   Fear of speed  \n",
      "408) Which is the National Game of Spain?      \n",
      "   Bull Fighting  \n",
      "409) Where is the Nokrek Biosphere Reserve Located?    \n",
      "   Megh alaya  \n",
      "410) Who is t he first Indian woman to wi n a medal at the Olympic \n",
      "Games?\n",
      "\n",
      "Distance: 1.0609\n",
      "Content: Praia do Cassino  Beach, Brazil  \n",
      "566) What is ellipsograph?         \n",
      "   Instrument for describing Ellipses  \n",
      "567) Which is the National Tree of USA?      \n",
      "   Oak Tree  \n",
      "568) Which country has the Longest Coastline in the World?   \n",
      "   Canada  \n",
      "569) Who wrote the Book, “2 States”?       \n",
      "   Chetan Bhagat  \n",
      "570) Where is Sariska Tiger Reserve Located?      \n",
      "   Alwar in Rajasthan  \n",
      "571) What is Optometer?         \n",
      "   Instrument for testing Vision  \n",
      "572) Who invented Typewriter?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Query and LLM Response (Run this cell repeatedly with different queries)\n",
    "query = \" What is Characterology? \"  \n",
    "\n",
    "# Perform similarity search\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "query_embedding_str =f\"[{','.join(map(str, query_embedding))}]\"\n",
    "\n",
    "cur.execute(\"SET hnsw.ef_search = 100;\") \n",
    "\n",
    "# Cast the query embedding to VECTOR type in the query\n",
    "cur.execute(\"\"\"\n",
    "    SET hnsw.ef_search = 100;\n",
    "    SELECT content, embedding <-> %s::vector AS distance\n",
    "    FROM documents\n",
    "    ORDER BY embedding <-> %s::vector\n",
    "    LIMIT 5;\n",
    "\"\"\", (query_embedding_str, query_embedding_str))\n",
    "similar = cur.fetchall()\n",
    "\n",
    "# Display results\n",
    "print(\"Top 5 similar document chunks:\")\n",
    "for content, distance in similar:\n",
    "    print(f\"Distance: {distance:.4f}\\nContent: {content}\\n\")\n",
    "\n",
    "# Prepare context for LLM\n",
    "context = \"\\n\\n\".join([content for content, _ in similar])\n",
    "\n",
    "# Get LLM response\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "response = llm_chain.run({\"context\": context, \"query\": query})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Sources:\n",
      "- Context provided\n",
      "\n",
      "Answer:\n",
      "Characterology is the study of personal character.\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.close()\n",
    "# conn.close()\n",
    "# print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
